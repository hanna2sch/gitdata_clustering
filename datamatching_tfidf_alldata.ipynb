{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib as mpl\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = \"gittables\"\n",
    "headerinfos =[]\n",
    "lengthinfo = []\n",
    "filder_files = os.listdir(inputfile)\n",
    "for filename in filder_files:\n",
    "    files = os.listdir(inputfile +'\\\\'+str(filename))\n",
    "    for file in files:\n",
    "        temp = []\n",
    "        check = True\n",
    "        no_lines = 0\n",
    "        with open(inputfile + '\\\\'+str(filename)+'\\\\'+str(file), \"r\", encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                if check:\n",
    "                    if not re.search(['[a-zA-Z]'], line):\n",
    "                        check = False\n",
    "                    else:\n",
    "                        headerinfos.append(line)\n",
    "                        check = False\n",
    "                if not check:\n",
    "                    no_lines += 1\n",
    "        lengthinfo.append(no_lines)\n",
    "joblib.dump(headerinfos, 'headerinfos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(headerline):\n",
    "    if \"\\\"\" in headerline and sum(map(lambda x : 1 if '\\\"' in x else 0, headerline)) % 2 == 0:\n",
    "        reststring=\"\"\n",
    "        escape=\"\"\n",
    "        positions = []\n",
    "        count = 0\n",
    "        for c in headerline:\n",
    "            if c == \"\\\"\":\n",
    "                positions.append(count)\n",
    "                count+=1\n",
    "            if len(positions) % 2 == 0 and c != \"\\\"\":\n",
    "                reststring += c\n",
    "            else:\n",
    "                escape += c\n",
    "        return splitting(reststring) + escape.split(\"\\\"\")\n",
    "    elif headerline[0] == \",\":\n",
    "        if \";\" in headerline:\n",
    "            temp = headerline.split(\",\")\n",
    "            return [item for sublist in [x.split(\";\") for x in temp] for item in sublist]\n",
    "        return headerline.split(\",\")\n",
    "    elif \";\" in headerline:\n",
    "        return headerline.split(\";\")\n",
    "    else:\n",
    "        return headerline.split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def tokenstemmanizer(text):\n",
    "    tokens = [word for w in nltk.sent_tokenize(text) for word in nltk.word_tokenize(w)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "def tokeizer(text):\n",
    "    tokens = [word.lower() for w in nltk.sent_tokenize(text) for word in nltk.word_tokenize(w)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "stemmed = []\n",
    "tokenized = []\n",
    "for head in headerinfos:\n",
    "    words_stemmed = tokenstemmanizer(head) \n",
    "    stemmed.extend(words_stemmed)\n",
    "    words_tokenized = tokeizer(head)\n",
    "    tokenized.extend(words_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dist_cosine_sim(vx,vy):\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    for x in vx:\n",
    "        for y in vy:\n",
    "            a += x*y\n",
    "            b += x*x\n",
    "            c += y*y\n",
    "    if (math.sqrt(b)*math.sqrt(c))==0:\n",
    "        return 0\n",
    "    return 1- (a / (math.sqrt(b)*math.sqrt(c)))\n",
    "\n",
    "#~62000 Stunden\n",
    "# mit cosine_similiarity: ~22386 Stunden ^= 2,5 Jahre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenstemmanizer, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(headerinfos) # scipy.sparse._csr.csr_matrix\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "#joblib.dump(terms, 'tfidf_terms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = joblib.load('matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = []\n",
    "k = tfidf_matrix.toarray()\n",
    "len_k = len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#terms = joblib.load('tfidf_terms.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['author' 'author titl' 'author titl url' 'comment' 'comment author'\n",
      " 'comment author titl' 'content' 'content creat' 'creat' 'id' 'id type'\n",
      " 'id type stori' 'parent' 'parent point' 'parent point comment' 'point'\n",
      " 'point comment' 'point comment author' 'stori' 'stori parent'\n",
      " 'stori parent point' 'titl' 'titl url' 'titl url content' 'type'\n",
      " 'type stori' 'type stori parent' 'url' 'url content' 'url content creat']\n"
     ]
    }
   ],
   "source": [
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from joblib import Memory\n",
    "## https://medium.com/dataturtles/disk-caching-using-joblib-51372056afac\n",
    "\n",
    "#cache_dir = \"C:\\\\Users\\\\hanna\\\\Documents\\\\temp\\\\Sem10\\\\lakehouse\\\\cachedir\"\n",
    "#mem = Memory(cache_dir)\n",
    "#func_mem = mem.cache(cosine_similarity, verbose = 0)\n",
    "#dist_mem = func_mem(tfidf_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 30\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#joblib.dump(km, 'doc_cluster.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "#num_clusters = 30\n",
    "#headerinfos = joblib.load('headerinfos.pkl')\n",
    "tfidf_matrix = joblib.load('matrix.pkl')\n",
    "#dist_allclusters = joblib.load('dist_allclusters.pkl')\n",
    "#pos = joblib.load(\"pos.pkl\")\n",
    "#color = joblib.load(\"color.pkl\")\n",
    "num_clusters=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterindexes = []\n",
    "for i in range(num_clusters):\n",
    "    clusterindexes.append([])\n",
    "for i in range(len(clusters)):\n",
    "    clusterindexes[clusters[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerinfos_by_cluster = []\n",
    "for i_cluster in clusterindexes:\n",
    "    temp = []\n",
    "    for index in i_cluster:\n",
    "        temp.append(headerinfos[index])\n",
    "    headerinfos_by_cluster.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_by_cluster = []\n",
    "k = tfidf_matrix.toarray()\n",
    "for cl_i in clusterindexes:\n",
    "    temp = []\n",
    "    for i in cl_i:\n",
    "        temp.append(k[i])\n",
    "    tfidf_matrix_by_cluster.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for arr_cl in tfidf_matrix_by_cluster:\n",
    "    if(len(arr_cl)) > 51000 or (len(arr_cl)==0):\n",
    "        print(count)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist_allclusters = []\n",
    "\n",
    "for arr_cl in tfidf_matrix_by_cluster:\n",
    "    if(len(arr_cl)) > 51000 or (len(arr_cl)==0):\n",
    "        continue\n",
    "    dist_allclusters.append(1-cosine_similarity(csr_matrix(arr_cl)))\n",
    "#joblib.dump(dist_allclusters, 'dist_allclusters.pkl')\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(dist_allclusters, 'dist_allclusters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dist_unique  = []\n",
    "for c in dist_allclusters:\n",
    "    if c not in dist_unique:\n",
    "        dist_unique.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "MDS()\n",
    "pos = []\n",
    "for c in dist_unique:\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "    pos.append(mds.fit_transform(c))\n",
    "#joblib.dump(pos, 'pos.pkl')\n",
    "#995m47.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustermean (clusterarray):\n",
    "    result = 0.0\n",
    "    for elem in clusterarray:\n",
    "        result += elem\n",
    "    return result/len(clusterarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "meanclust_dist = []\n",
    "for clust in dist_allclusters:\n",
    "    if len(clust) == 0:\n",
    "        continue\n",
    "    meanclust_dist.append(np.sum(clust)/(np.sum([len(cl) for cl in clust])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "pos_mean = joblib.load(\"pos_mean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(pos, 'pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#joblib.dump(pos_mean, 'pos_mean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "color = {}\n",
    "r = lambda: random.randint(0,255)\n",
    "for i in range(len(meanclust_dist)):\n",
    "    color[i]='#{:02x}{:02x}{:02x}'.format(r(), r(), r())\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(color, 'color.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count = 0\n",
    "all_x = []\n",
    "all_y = []\n",
    "all_labels =[]\n",
    "all_titles = []\n",
    "for cluster in pos:\n",
    "    xs, ys = cluster[:,0], cluster[:, 1]\n",
    "    all_x.append([(x) for x in xs])\n",
    "    all_y.append([(y) for y in ys])\n",
    "    for i in range(len(xs)):\n",
    "        all_labels.append(count)\n",
    "        all_titles.append(str(count))\n",
    "    count+=1\n",
    "\n",
    "all_xs = [item for sublist in all_x for item in sublist]\n",
    "all_ys = [item for sublist in all_y for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ys = meanclust_dist\n",
    "all_xs = range(len(meanclust_dist))\n",
    "all_labels = all_xs\n",
    "all_titles = [str(c) for c in all_xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "df = pd.DataFrame(dict(x=all_xs, y=all_ys, label=all_labels, title = all_titles)) \n",
    "groups = df.groupby('label')\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "            label=name, color=color[name], \n",
    "            mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',         \n",
    "        which='both',      \n",
    "        bottom='off',      \n",
    "        top='off',        \n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         \n",
    "        which='both',      \n",
    "        left='off',      \n",
    "        top='off',         \n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)\n",
    "for i in range(len(df)):\n",
    "    ax.text(df.iloc[i]['x'], df.iloc[i]['y'], df.iloc[i]['title'], size=8)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  x             y  label title\n",
      "0     -3.010915e-07  8.795091e-07      0     0\n",
      "1     -3.010917e-07  8.795060e-07      0     0\n",
      "2     -3.010905e-07  8.795095e-07      0     0\n",
      "3     -3.010912e-07  8.795095e-07      0     0\n",
      "4     -3.010895e-07  8.795088e-07      0     0\n",
      "...             ...           ...    ...   ...\n",
      "23619 -3.010902e-07  8.795064e-07      0     0\n",
      "23620 -3.010897e-07  8.795089e-07      0     0\n",
      "23621 -3.010903e-07  8.795068e-07      0     0\n",
      "23622 -3.010895e-07  8.795102e-07      0     0\n",
      "23623 -3.010896e-07  8.795093e-07      0     0\n",
      "\n",
      "[23624 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dict(x=all_xs, y=all_ys, label=all_labels, title = all_titles))\n",
    "df_ = df[df['label'] == 0]\n",
    "print(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#%matplotlib inline \n",
    "for isf in range(len(meanclust_dist)):\n",
    "    df = pd.DataFrame(dict(x=all_xs, y=all_ys, label=all_labels, title = all_titles))\n",
    "    df = df[df['label'] == isf]\n",
    "    groups = df.groupby('label')\n",
    "    fig, ax = plt.subplots(figsize=(17, 9))\n",
    "    ax.margins(0.05)\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "                label=name, color=color[name], \n",
    "                mec='none')\n",
    "        ax.set_aspect('auto')\n",
    "        ax.tick_params(\\\n",
    "            axis= 'x',         \n",
    "            which='both',      \n",
    "            bottom='off',      \n",
    "            top='off',        \n",
    "            labelbottom='off')\n",
    "        ax.tick_params(\\\n",
    "            axis= 'y',         \n",
    "            which='both',      \n",
    "            left='off',      \n",
    "            top='off',         \n",
    "            labelleft='off')\n",
    "        \n",
    "    ax.legend(numpoints=1)\n",
    "    for i in range(len(df)):\n",
    "        ax.text(df.iloc[i]['x'], df.iloc[i]['y'], df.iloc[i]['title'], size=8)  \n",
    "    plt.savefig('cluster'+ str(isf)+'.png')\n",
    "    plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnames_pos(clusternr, x_lower, x_higher, y_lower,y_higher, position, headerinf):\n",
    "    clusterid_headerinfo = clusternr+4\n",
    "    pos_clusterofinterest = pos[clusternr]\n",
    "    headerinfos_clusterofinterest = headerinf[clusterid_headerinfo]\n",
    "    #print(len(headerinfos_clusterofinterest))\n",
    "    x_lowerbound= x_lower\n",
    "    x_higherbound = x_higher\n",
    "    y_lowerbound = y_lower\n",
    "    y_higherbound = y_higher\n",
    "    #get indixes for lookup in headerinfo for this range\n",
    "    indexesofinterest = []\n",
    "    count = 0\n",
    "    for c in pos_clusterofinterest:\n",
    "        if c[0]>x_lowerbound and c[0]<x_higherbound and c[1]>y_lowerbound and c[1]<y_higherbound:\n",
    "            indexesofinterest.append(headerinfos_clusterofinterest[count])\n",
    "        count += 1\n",
    "    print(len(indexesofinterest))\n",
    "    return list(set(indexesofinterest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (getnames_pos(3, -0.3, -0.2, -0.03, 0.016, pos, headerinfos_by_cluster))\n",
    "for gg in g:\n",
    "    print(gg)\n",
    "h = getnames_pos(3, 0.25,0.3,-0.03, 0.016, pos, headerinfos_by_cluster)\n",
    "for gg in h:\n",
    "    print(gg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterid = 3\n",
    "g1 = getnames_pos(clusterid, -0.3, -0.1, -0.3, 0.3, pos, headerinfos_by_cluster)\n",
    "g2 = getnames_pos(clusterid, -0.06, 0.3, -0.3, 0.3, pos, headerinfos_by_cluster)\n",
    "g3= getnames_pos(clusterid, -0.3, 0.3, -0.3, -0.11, pos, headerinfos_by_cluster)\n",
    "g4= getnames_pos(clusterid, -0.3, 0.3, 0.1, 0.3, pos, headerinfos_by_cluster)\n",
    "g=[]\n",
    "g.append(g1)\n",
    "g.append(g2)\n",
    "g.append(g3)\n",
    "g.append(g4)\n",
    "gg=[item for sublist in g for item in sublist]\n",
    "gg=list(set(gg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gg))\n",
    "print(len([x for x in gg if x.lower().__contains__('id')]))\n",
    "for l in gg:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g14a = getnames_pos(14,0.18,0.3,-0.2,0.0, pos,headerinfos_by_cluster) #90 punkte, die berücksichtig werden\n",
    "g14b = getnames_pos(14, -0.3,-0.17,0.0,0.1, pos, headerinfos_by_cluster) # 22 Punkte, die berücksichtigt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(g14a))\n",
    "print(len (g14b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
